{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5utr, 3utr or cds:3utr\n",
      "size analyzed using 17 for all, 22 for 22G, and 26 for 26mer:17\n",
      "WT:0320toom_all\n",
      "Normalization sample for WT:0320toom_all\n",
      "Mutant:0320tocsr1om_all\n",
      "Normalization sample for Mutant:0320tocsr1om_all\n",
      "0320toom_all cdna_coding total genes: 16100 \n",
      "\n",
      "\n",
      "0320tocsr1om_all cdna_coding total genes: 16100 \n",
      "\n",
      "\n",
      "8804 genes with at least 1 small RNAs in either 0320toom_all and/or 0320tocsr1om_all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3.4\n",
    "# Python variables are local, if not otherwise declared\n",
    "\n",
    "'''\n",
    "This script compares deep-seq reads of transcripts - updated 06/03/16.\\n\n",
    "This script identifies all the transcripts with at least a given number of reads in either the WT \\\n",
    "or the mutant, and return a list of transcripts with a ratio of mut/(wt+mut) below a given value in a file \\\n",
    "named as mutant_wt_type_strand_small-RNA-cutoff_normalization-standard_depletion-threshold.txt\\n\n",
    "Copy this script into a working folder with all the sample_named subfolders each containing\n",
    "two files: sum_sample.txt and sum_sample_17_cdna_type_normed.txt\\n\n",
    "Four files are also required in the working folder containing this script\n",
    "wago_targets_at_least_three_overlap.txt\n",
    "csr1_targets_at_least_three_overlap.txt\n",
    "ERGO-1_targets.txt\n",
    "alg34_fog2_20_twice.txt\\n\n",
    "There are 6 normalization methods:\n",
    "1) nons; 2) cose,coan,coto; 3) mir; 4) tot\\n\n",
    "'''\n",
    "\n",
    "import os\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "\n",
    "utr = input('5utr, 3utr or cds:')\n",
    "grp = 'all'\n",
    "tp = 'cdna_coding' # cdna_coding, cdna_miRNA, cdna_u21RNA, ......\n",
    "stan = 'mir' # normalization standard, using tot, nons, cose (coding sen), coan (coding anti),coto (coding tot), mir, or 21U\n",
    "strand ='an'; # se for sense, an for anti, and all for both sense and anti\n",
    "cut=1; # read cutoff / gene\n",
    "thres=2; # depletion ratio (0-1): MT/(MT+WT) if more than 1, that means all\n",
    "\n",
    "# wago, csr, alg, ergo, other = 'blue','red','cyan','black','green'\n",
    "\n",
    "min_size = input('size analyzed using 17 for all, 22 for 22G, and 26 for 26mer:')\n",
    "\n",
    "sam1 = input('WT:')\n",
    "sam11 = input('Normalization sample for WT:')\n",
    "sam2 = input('Mutant:')\n",
    "sam22 = input('Normalization sample for Mutant:')\n",
    "\n",
    "### name the output directory\n",
    "names = [sam1, sam2]\n",
    "names = sorted(names)\n",
    "name = names[0]+'_'+names[1]\n",
    "\n",
    "def main():\n",
    "    ### normalization\n",
    "    wt = norm_data(sam1, sam11)\n",
    "    mut = norm_data(sam2, sam22)\n",
    "\n",
    "    #if not os.path.isdir(name):\n",
    "    #    os.mkdir(name)\n",
    "  \n",
    "    ### make a directory, if there already exists a file with the directory name, raise Error  \n",
    "    try:\n",
    "        os.makedirs('small_RNA_comparison/'+name)\n",
    "    except OSError:\n",
    "        if not os.path.isdir('small_RNA_comparison/'+name):\n",
    "            raise\n",
    "        \n",
    "    ### ????? cut off 1, remove genes which have less than 1 read\n",
    "    wt_keys = [k for k in wt.keys()]\n",
    "    for ks in wt_keys:\n",
    "        if wt[ks] < cut and mut[ks] < cut:\n",
    "            del wt[ks]\n",
    "            del mut[ks]\n",
    "            \n",
    "        \n",
    "    ### how many genes have at least 1 read in either mut and/or wt\n",
    "    count = len(wt)\n",
    "    for ks in mut.keys():\n",
    "        if ks not in wt.keys():\n",
    "            count += 1\n",
    "    print (count, 'genes with at least', cut, 'small RNAs in either', sam1, 'and/or', sam2, '\\n')\n",
    "\n",
    "\n",
    "    depe = {}\n",
    "    for ks in mut.keys():\n",
    "        depe[ks] = mut[ks]/(wt[ks]+mut[ks])\n",
    "\n",
    "    # sorted(depe.items(), key=lambda depe: depe[1])\n",
    "    sorted_depe = sorted(depe.items(), key = operator.itemgetter(1))\n",
    "\n",
    "    f = open('small_RNA_comparison/'+name+'/'+sam2+'_'+sam1+'_'+grp+'_'+utr+'_'+tp+'_'+str(cut)+'_'+stan+'_'+str(thres)+'.txt', 'wt')\n",
    "\n",
    "    #orig_stdout = sys.stdout\n",
    "    #sys.stdout = f\n",
    "\n",
    "    for (key, val) in sorted_depe: # *, 0 or more; +, 1 or more; ?, 0 or 1\n",
    "        if not val <= thres:\n",
    "            continue\n",
    "        m = str(round(mut[key],4))\n",
    "        w = str(round(wt[key],4))\n",
    "        r = str(round(depe[key],4))\n",
    "    \n",
    "        f.write(key+'\\t'+m+'\\t'+w+'\\t'+r+'\\n') \n",
    "        #print (ks+'\\t'+m+'\\t'+w+'\\t'+r+'\\n')\n",
    "    \n",
    "    #sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "\n",
    "    #sorted_depe.clear() # also clear depe\n",
    "    del sorted_depe[:]\n",
    "\n",
    "    file = sam2+'_'+sam1+'_'+grp+'_'+utr+'_'+tp+'_'+str(cut)+'_'+stan+'_'+str(thres)+'.txt'\n",
    "    label_gene(file)\n",
    "\n",
    "    \n",
    "def norm(sam, stan):\n",
    "    # get the normalization ratio\n",
    "    geex, struc, cose, coan, coto, mir, u21 = 0, 0, 0, 0, 0, 0, 0\n",
    "    file = sam+'/sum_'+sam+'.txt'\n",
    "    with open (file) as f:\n",
    "        for line in f:\n",
    "            #line = re.sub(r'\\s+$', r'', line)\n",
    "            line = line.rstrip()\n",
    "            if re.search(r'^geex\\t\\S+\\t\\S+\\t\\S+', line):\n",
    "                mch = re.search(r'^geex\\t\\S+\\t\\S+\\t(\\S+)', line) # all\n",
    "                geex = float(mch.group(1))\n",
    "            if (re.search(r'^struc\\t\\S+\\t\\S+\\t\\S+', line)):\n",
    "                mch = re.search(r'^struc\\t(\\S+)\\t\\S+\\t\\S+', line) # sense\n",
    "                struc = float(mch.group(1))\n",
    "            if (re.search(r'^coding\\t\\S+\\t\\S+\\t\\S+', line)):\n",
    "                mch = re.search(r'^coding\\t(\\S+)\\t(\\S+)\\t(\\S+)', line)\n",
    "                cose = float(mch.group(1)); coan = float(mch.group(2)); coto = float(mch.group(3))\n",
    "            if (re.search(r'^miRNA\\t\\S+\\t\\S+\\t\\S+', line)):\n",
    "                mch = re.search(r'miRNA\\t(\\S+)\\t\\S+\\t\\S+', line) # sense\n",
    "                mir = float(mch.group(1))\n",
    "            if (re.search(r'^u21RNA\\t\\S+\\t\\S+\\t\\S+', line)):\n",
    "                mch = re.search(r'u21RNA\\t(\\S+)\\t\\S+\\t\\S+', line) # sense\n",
    "                u21 = float(mch.group(1))\n",
    "            if (re.search(r'^star-miRNA', line)):\n",
    "                break\n",
    "    nons = geex - struc\n",
    "        \n",
    "    print ('''total %.2f\n",
    "              sense struc %.2f\n",
    "              non-struc %.2f\n",
    "              sense coding %.2f\n",
    "              anti coding %.2f\n",
    "              total coding %.2f\n",
    "              sense miRNA %.2f\n",
    "              sense 21U-RNA %.2f\\n''' % (geex, struc, nons, cose, coan, coto, mir, u21))\n",
    "        \n",
    "    if (stan == 'mir'):\n",
    "        ratio = 1000000/mir\n",
    "    elif (stan == 'cose'):\n",
    "        ratio = 5000000/cose\n",
    "    elif (stan == 'coan'):\n",
    "        ratio = 2000000/coan\n",
    "    elif (stan == 'coto'):\n",
    "        ratio = 5000000/coto\n",
    "    elif (stan == 'nons'):\n",
    "        ratio = 5000000/nons\n",
    "    elif (stan == 'tot'):\n",
    "        ratio = 5000000/geex\n",
    "    elif (stan == '21U'):\n",
    "        ratio = 500000/u21\n",
    "    \n",
    "    print ('Normalization ratio', ratio, '\\n\\n')\n",
    "    \n",
    "    return ratio\n",
    "\n",
    "\n",
    "def norm_data(sam, nsam):\n",
    "    # returns a dictionary\n",
    "    # 'sum_0320tocsr1om_all_all_csr1_3utr_17_cdna_coding_mir.txt' what's this file? not normalized ??? change ratio to 1 ?\n",
    "    # 'sum_0320tocsr1om_all_17_cdna_coding.txt' how about this ?\n",
    "    al = {}\n",
    "    # ra = norm(nsam, stan)\n",
    "    ra = 1\n",
    "    # print ('using', nsam, ',', sam, 'normaization ratio is', ra, '\\n\\n')\n",
    "    file = sam+'/sum_'+sam+'_'+goprp+'_'+utr+'_'+min_size+'_'+tp+'_'+stan+'.txt'\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            #line = re.sub(r'\\s+$', r'', line)\n",
    "            line = line.rstrip()\n",
    "            if line.startswith('>'):\n",
    "                continue\n",
    "            lst = line.split('\\t')\n",
    "            gene = lst[0]+'\\t'+lst[1]\n",
    "            if (strand == 'se'):\n",
    "                al[gene] = float(lst[2])*ra\n",
    "            elif (strand == 'an'):\n",
    "                al[gene] = float(lst[3])*ra\n",
    "            elif (strand == 'all'):\n",
    "                al[gene] = float(lst[4])*ra\n",
    "    count = len(al)\n",
    "\n",
    "    print (sam, tp, 'total genes:', count, '\\n\\n')\n",
    "    \n",
    "    return al\n",
    "\n",
    "\n",
    "def label_gene(file):\n",
    "    wago = {}; csr = {}; ergo = {}; alg = {}; emb = {}\n",
    "    with open('wago_targets_at_least_three_overlap.txt', 'rt') as f:\n",
    "        for line in f:\n",
    "            lst = line.rstrip().split('\\t')\n",
    "            wago[lst[0]]=1\n",
    "    \n",
    "    with open('csr1_targets_at_least_three_overlap.txt', 'rt') as f:\n",
    "        for line in f:\n",
    "            lst = line.rstrip().split('\\t')\n",
    "            csr[lst[0]]=1\n",
    "    \n",
    "    with open('ERGO-1_targets.txt', 'rt') as f:\n",
    "        for line in f:\n",
    "            lst = line.rstrip().split('\\t')\n",
    "            ergo[lst[0]]=1\n",
    "    \n",
    "    with open('alg34_fog2_20_twice.txt', 'rt') as f:\n",
    "        for line in f:\n",
    "            lst = line.rstrip().split('\\t')\n",
    "            alg[lst[0]]=1\n",
    "\n",
    "    #with open('embro_targets.txt', 'rt') as f:\n",
    "    #    for line in f:\n",
    "    #        lst = line.rstrip().split('\\t')\n",
    "    #        gene = lst[0]+'\\t'+lst[1]\n",
    "    #        emb[gene]=1   \n",
    "    \n",
    "\n",
    "    out = re.sub(r'\\.txt', r'_labeled.txt', file)\n",
    "    outfile = open('small_RNA_comparison/' + name + '/' + out, 'wt')\n",
    "    \n",
    "    infile = 'small_RNA_comparison/' + name + '/' + file\n",
    "    with open(infile) as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            lst = line.split('\\t')\n",
    "            outfile.write(line + '\\t')\n",
    "            if lst[0] in wago.keys():\n",
    "                outfile.write('wago' + '\\t')\n",
    "            else:\n",
    "                outfile.write('Not' + '\\t')\n",
    "            \n",
    "            if lst[0] in csr.keys():\n",
    "                outfile.write('csr' + '\\t')\n",
    "            else:\n",
    "                outfile.write('Not' + '\\t')\n",
    "                \n",
    "            if lst[0] in ergo.keys():\n",
    "                outfile.write('ergo' + '\\t')\n",
    "            else:\n",
    "                outfile.write('Not' + '\\t')\n",
    "                \n",
    "            if lst[0] in alg.keys():\n",
    "                outfile.write('alg' + '\\n')\n",
    "            else:\n",
    "                outfile.write('Not' + '\\n')\n",
    "                \n",
    "            #if lst[0] in emb.keys():\n",
    "            #    outfile.write('emb' + '\\n')\n",
    "            #else:\n",
    "            #    outfile.write('Not' + '\\n')\n",
    "        \n",
    "    outfile.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    \n",
    "### draw the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-957cf554a9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEXIST\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'test'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs('test')\n",
    "except OSError:\n",
    "    if not os.path.isdir('test'):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x=1; y=2\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "names = [1,2,5,3]\n",
    "names = sorted(names)\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " '0320tocsr1om_all_0320toom_all_all_3utr_cdna_coding_an_1_mir_2_labeled.txt',\n",
       " '0320tocsr1om_all_17_cdna_coding_normed.txt',\n",
       " '0320tocsr1om_all_3utr_17_cdna_coding_mir.txt',\n",
       " '7_count_utr_CDS_reads.ipynb',\n",
       " '8_transcript_comparison.ipynb',\n",
       " 'alg34_fog2_20_twice.txt',\n",
       " 'ceWS215_3utr_pos.txt',\n",
       " 'ceWS215_CDS_3utr_filtered.txt',\n",
       " 'ceWS215_CDS_5utr_filtered.txt',\n",
       " 'ceWS215_CDS_pos.txt',\n",
       " 'ceWS215_gdna.fa',\n",
       " 'csr1_targets_at_least_three_overlap.txt',\n",
       " 'ERGO-1_targets.txt',\n",
       " 'folder',\n",
       " 'rank_csr_targets.ipynb',\n",
       " 'ranked.txt',\n",
       " 'read_fastq.ipynb',\n",
       " 'sum_0320tocsr1om_all.txt',\n",
       " 'sum_3utr_read_CSR1_targets_mir.txt',\n",
       " 'transcript_comparison_082814.pl',\n",
       " 'Untitled0.ipynb',\n",
       " 'wago_targets_at_least_three_overlap.txt']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try: \n",
    "    os.mdir('ttt')\n",
    "except OSError:\n",
    "    if not os.path.isdir('ttt'):\n",
    "        raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'has_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b732ae871486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'has_key'"
     ]
    }
   ],
   "source": [
    "name = {'a':1}\n",
    "name.has_key('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.598"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.5975,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('folder/'+ 'mmm.txt', 'wt')\n",
    "f.write('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "name = 'N2csr1'\n",
    "sam1 = 'N2'\n",
    "sam2 = 'csr1'\n",
    "grp = 'all'\n",
    "utr = '3utr'\n",
    "tp = 'coding'\n",
    "cut = 1\n",
    "stan = 'mir'\n",
    "thres = 2\n",
    "\n",
    "f = open('folder/'+name+'/'+sam2+'_'+sam1+'_'+grp+'_'+utr+'_'+tp+'_'+str(cut)+'_'+stan+'_'+str(thres)+'.txt', 'wt')\n",
    "f.write('love')\n",
    "f.write('u')\n",
    "f.write('forever'+'\\n')\n",
    "f.write('haha'+'\\n')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "sys.stdout = f\n",
    "\n",
    "print ('Dito')\n",
    "print ('Only')\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "print ('too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('d', 2), ('e', 3), ('b', 5)]\n",
      "[('a', 1), ('b', 5), ('d', 2), ('e', 3)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "x = {'a':1, 'b':5, 'e':3, 'd':2}\n",
    "y = {'a':1, 'b':5, 'e':3, 'd':2}\n",
    "\n",
    "\n",
    "x = sorted(x.items(), key=lambda x: x[1])\n",
    "y = sorted(y.items(), key = operator.itemgetter(0))\n",
    "\n",
    "print (x)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "x = '1000'\n",
    "pattern = r'\\.?0+$'\n",
    "su = r''\n",
    "\n",
    "re.sub(pattern, su, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.000/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stuff': 'things'}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "d = {\"stuff\": \"things\"}\n",
    "d2 = d\n",
    "d = {}\n",
    "print (d2)\n",
    "\n",
    "d = {\"stuff\": \"things\"}\n",
    "d2 = d\n",
    "d.clear()\n",
    "print (d2)\n",
    "\n",
    "d = {\"stuff\": \"things\"}\n",
    "d2 = d\n",
    "d2.clear()\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder/N2csr1/csr1_N2_all_3utr_coding_1_mir_2.txt wt\n",
      "csr1_N2_all_3utr_coding_1_mir_2.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('folder/'+name+'/'+sam2+'_'+sam1+'_'+grp+'_'+utr+'_'+tp+'_'+str(cut)+'_'+stan+'_'+str(thres)+'.txt', 'wt')\n",
    "\n",
    "file = sam2+'_'+sam1+'_'+grp+'_'+utr+'_'+tp+'_'+str(cut)+'_'+stan+'_'+str(thres)+'.txt'\n",
    "\n",
    "print (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "geex, struc, cose, coan, coto, mir, u21, nons = 0,0,0,0,0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-90-daddf88d2c30>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-daddf88d2c30>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print ('total %.2f\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "        print ('''total %.2f\n",
    "sense struc %.2f\n",
    "non-struc %.2f\n",
    "sense coding %.2f\n",
    "anti coding %.2f\n",
    "total coding %.2f\n",
    "sense miRNA %.2f\n",
    "sense 21U-RNA %.2f\\n''' % (geex, struc, nons, cose, coan, coto, mir, u21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "y = 7\n",
    "import sys\n",
    "name = 'N2csr1'\n",
    "sam1 = 'N2'\n",
    "sam2 = 'csr1'\n",
    "grp = 'all'\n",
    "utr = '3utr'\n",
    "tp = 'coding'\n",
    "cut = 1\n",
    "stan = 'mir'\n",
    "thres = 2\n",
    "\n",
    "wt = {}\n",
    "def test(wt):\n",
    "    wt = {'a':1}\n",
    "    z = 'folder/'+name+'/'+sam2+'_'+sam1+'_'+grp+'_'+utr+'_'+tp+'_'+str(cut)+'_'+stan+'_'+str(thres)+'.txt'\n",
    "    #print (z)\n",
    "    return wt\n",
    "    \n",
    "m = test(wt)\n",
    "\n",
    "print (m)\n",
    "print (wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = 7\n",
    "def test(x):\n",
    "    y = x + 1\n",
    "    print (y)\n",
    "    \n",
    "test(y)\n",
    "print (y)\n",
    "\n",
    "\n",
    "def test(x):\n",
    "    global y # parse out\n",
    "    y = x + 1\n",
    "    print (y)\n",
    "    \n",
    "test(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script compares deep-seq reads of transcripts - updated 06/03/11 by WG.\n",
      "\n",
      "This script identifies all the transcripts with at least a given number of reads in either the WT or the mutant, and return a list of transcripts with a ratio of mut/(wt+mut) below a given value in a file named as mutant_wt_type_strand_small-RNA-cutoff_normalization-standard_depletion-threshold.txt\n",
      "\n",
      "Copy this script into a working folder with all the sample_named subfolders each containing\n",
      "two files: sum_sample.txt and sum_sample_17_cdna_type_normed.txt\n",
      "\n",
      "Four files are also required in the working folder containing this script\n",
      "wago_targets_at_least_three_overlap.txt\n",
      "csr1_targets_at_least_three_overlap.txt\n",
      "ERGO-1_targets.txt\n",
      "alg34_fog2_20_twice.txt\n",
      "\n",
      "There are 6 normalization methods:\n",
      "1) nons; 2) cose,coan,coto; 3) mir; 4) tot\n",
      "\n",
      "\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print (\n",
    "'''\n",
    "This script compares deep-seq reads of transcripts - updated 06/03/11 by WG.\\n\n",
    "This script identifies all the transcripts with at least a given number of reads in either the WT \\\n",
    "or the mutant, and return a list of transcripts with a ratio of mut/(wt+mut) below a given value in a file \\\n",
    "named as mutant_wt_type_strand_small-RNA-cutoff_normalization-standard_depletion-threshold.txt\\n\n",
    "Copy this script into a working folder with all the sample_named subfolders each containing\n",
    "two files: sum_sample.txt and sum_sample_17_cdna_type_normed.txt\\n\n",
    "Four files are also required in the working folder containing this script\n",
    "wago_targets_at_least_three_overlap.txt\n",
    "csr1_targets_at_least_three_overlap.txt\n",
    "ERGO-1_targets.txt\n",
    "alg34_fog2_20_twice.txt\\n\n",
    "There are 6 normalization methods:\n",
    "1) nons; 2) cose,coan,coto; 3) mir; 4) tot\\n\n",
    "''')\n",
    "\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.listdir()\n",
    "n = 'xxx'\n",
    "\n",
    "os.makedirs('folder/'+n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(n)\n",
    "except OSError:\n",
    "    if not os.path.isdir(n):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    zz = 't'\n",
    "    mm(zz)\n",
    "    \n",
    "def mm(zz):\n",
    "    print (zz)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x, y = 1, 3\n",
    "t = x\n",
    "x = 7\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 3, 'a': 2} {'b': 2, 'a': 1}\n"
     ]
    }
   ],
   "source": [
    "w = {'a':2, 'b': 3, 'c':0.5}\n",
    "mu = {'a':1, 'b': 2, 'c':0.7}\n",
    "\n",
    "w_keys = [k for k in w.keys()]\n",
    "\n",
    "for k in w_keys:\n",
    "    if w[k] < cut and mu[k] < cut:\n",
    "        del w[k]\n",
    "        del mu[k]\n",
    "            \n",
    "print (w, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-73a9823c2a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmuo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcut\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "wo = {'a':2, 'b': 3, 'c':0.5}\n",
    "muo = {'a':1, 'b': 2, 'c':0.7}\n",
    "\n",
    "w, mu = wo, muo\n",
    "\n",
    "for k in wo.keys():\n",
    "    if w[k] < cut and mu[k] < cut:\n",
    "        del w[k]\n",
    "        del mu[k]\n",
    "            \n",
    "print (w, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "5 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k, v in [(2,3),[5,7]]:\n",
    "    print (k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "depe = {'a':1, 'b':3, 'c':2}\n",
    "\n",
    "sorted_depe = sorted(depe.items(), key = operator.itemgetter(1), reverse = True)\n",
    "\n",
    "print (sorted_depe[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'd', 'e', 'e', 'c', 'a', 'a', 'a', 'a', 'a', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "x = 'abcddeecaaaaade'\n",
    "l = list(x)\n",
    "print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 6)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "letters = collections.Counter(x)\n",
    "sorted_letters = sorted(letters.items(), key = operator.itemgetter(1), reverse = True)\n",
    "print (sorted_letters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
